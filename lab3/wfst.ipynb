{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Well-Formed Substring Tables"
      ],
      "metadata": {
        "id": "SPoBQGBoysiD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is a type of chart parsing (in Romanian: parser cu agenda). It is used to avoid rebuilding subtrees that are already correct. The previous parsers that used backtracking in their algorithm could process subtrees again because there is a wrong assumption in the subtrees created before them. It's in backtracking's nature to delete(forget) all the computing it made for a wrong prefix in the solution.\n",
        "\n",
        "Each time we build a subtree we save it in a \"table\" and it will be reused when it's needed. An idea of implementation is given in the NLTK book *Natural Language Processing with Python* by Steven Bird, Ewan Klein, and Edward Loper (2009).\n",
        "\n",
        "1. Supposing we have a sentence of n words, we create a matrix of (n+1)^2 elements. Let's call this matrix T. The meaning of this matrix is that T[ i ][ j ] wiil contan the root of the subtree containing all the words from i to j-1. At first, the matrix will be empty (initialised with null values), except elements T[ i ][ i+1 ] that will contain the i-th word.\n",
        "\n",
        "2. Next we continuosly apply the productions completing the table, until no more changes in the table are made. In order to complete T[ i ][ j ] with a label, we must have a number k in [0, n] such that T[ i ][ k ] and T[ k ][ j ] are both completed (let's say T[ i ][ k ] is B and T[ k ][ j ] is C) and a production A -> B C. In this case, we'll assign T[ i ][ j ]=A. We may have multiple cases for the same line i and column j (from a different reduction of the trees). In this case, we save all the values, so it is better to consider T[ i ][ j ] being a list of symbols. An even better representantion, in order to easily obtain the responsible productions for the end tree, would be to have the whole production (A -> B C) saved in T[ i ][ j ], for example by saving it's id (assuming that all the grammar's productions have an id).\n",
        "\n",
        "3. If we have B -> C in T[ i ][ j ] and there exists a production A -> B, we add A -> B to T[ i ][ j ].\n",
        "\n",
        "4. How to treat productions with a number of terminals not equal to 2: we may process the grammar and reform the productions, by adding auxiliary ones in order to obtain only two nodes in each production; for example \"A-> B C D\" can be changed into \"A-> B NewT1\" and \"NewT1-> C D\", where NewT1 is a new terminal used only for this production.\n",
        "\n",
        "5. The algorithm finishes when no more reductions can be made. If we've obtained S (the sentence node) in T[0][n] we have succesfully parsed the sentence.\n",
        "\n",
        "It is not mandatory to use a matrix, you can save the agenda with a list of subtrees, however you still need to save (in that structure) the indexes for the leaves contained by each subtree.\n",
        "\n",
        "After you build the matrix T for an input sentence you need to construct all the parsing trees saved in T for the sentence."
      ],
      "metadata": {
        "id": "lBoiXueSyzMT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYDJlxnKyoxi"
      },
      "outputs": [],
      "source": []
    }
  ]
}